{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been renamed, grouped into folders, and moved to the new directory.\n",
      "Files have been renamed, grouped into folders, and moved to the new directory.\n",
      "Files have been renamed, grouped into folders, and moved to the new directory.\n",
      "Files have been renamed, grouped into folders, and moved to the new directory.\n"
     ]
    }
   ],
   "source": [
    "# Define source and destination directories\n",
    "src_dir = \"./Data/Preprocessed\"\n",
    "dst_dir = \"./Data/Processed\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all files in the source directory\n",
    "\n",
    "for folder in os.listdir(src_dir):\n",
    "    folder_path = os.path.join(src_dir, folder)\n",
    "    folder_dst_dir = os.path.join(dst_dir, folder)\n",
    "\n",
    "    os.makedirs(folder_dst_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if \"filtered\" in filename:\n",
    "            continue\n",
    "\n",
    "        if 'Ai213' in filename and ('.CSV' in filename or '.csv' in filename):\n",
    "\n",
    "            start_index = filename.find('Ai213')\n",
    "            # Remove all characters before 'Ai213' and change .CSV to .csv\n",
    "            new_filename = filename[start_index:].replace('.CSV', '.csv')\n",
    "\n",
    "            # Extract the grouping pattern Ai213_x=x_#x using regex\n",
    "            match = re.search(r'Ai213_\\d+-\\d+_#\\d+', new_filename)\n",
    "            if match:\n",
    "                if \"Side_viewDLC_Resnet50\" in filename:\n",
    "                    new_filename = match.group(0) + \"_Pose_Data.csv\"\n",
    "                \n",
    "                # Create a subdirectory based on the matched pattern\n",
    "                subfolder_name = match.group(0)\n",
    "                subfolder_path = os.path.join(folder_dst_dir, subfolder_name)\n",
    "                os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "                # Construct full file paths\n",
    "                old_filepath = os.path.join(folder_path, filename)\n",
    "                new_filepath = os.path.join(subfolder_path, new_filename)\n",
    "\n",
    "                # Move and rename the file\n",
    "                shutil.copy(old_filepath, new_filepath)\n",
    "\n",
    "    print(\"Files have been renamed, grouped into folders, and moved to the new directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df(df_path):\n",
    "    df = pd.read_csv(df_path, index_col=0)\n",
    "    likelihood_cols = [col for col in df.columns if 'likelihood' in col]\n",
    "    df['total_likelihood'] = df[likelihood_cols].sum(axis=1)\n",
    "\n",
    "    # reduced_df = df.groupby(df.index // 8).first().reset_index(drop=True)\n",
    "    # Group rows into groups of 8 and select the one with the highest total likelihood in each group\n",
    "    grouped = df.groupby(df.index // 8)\n",
    "\n",
    "    reduced_df = grouped.apply(lambda group: group.loc[group['total_likelihood'].idxmax()])\n",
    "\n",
    "    bool_columns = ['Is_Voiding', 'Shock_Start', 'Shock_End', 'Tone_Start', 'Tone_End']\n",
    "    for col in bool_columns:\n",
    "        reduced_df[col] = grouped[col].any()\n",
    "\n",
    "    # Drop the 'total_likelihood' column used for selection\n",
    "    reduced_df = reduced_df.drop(columns=['total_likelihood'])\n",
    "    reduced_df = reduced_df.reset_index(drop=True)\n",
    "    reduced_df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_void_timing(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df['seconds'] = df['Var4'].str.extract(r'(\\d+\\.\\d+)')\n",
    "    df = df[['seconds']]\n",
    "    df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_pose_data(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    body_parts = df.iloc[0, 1:] \n",
    "    coords = df.iloc[1, 1:] \n",
    "\n",
    "    # Initialize an empty list to hold the new column names\n",
    "    new_columns = []\n",
    "    new_columns.append(f'Image')\n",
    "    # Create new column names based on body parts and coordinates\n",
    "    for part, coord in zip(body_parts, coords):\n",
    "        new_columns.append(f'{part}_{coord}')\n",
    "    df.columns = new_columns\n",
    "    df = df[2:]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(['Image'], axis=1)\n",
    "\n",
    "    df.to_csv(df_path)\n",
    "    # df_drop = df[[col for col in df.columns if col.endswith('_x') or col.endswith('_y')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time_df(df_path):\n",
    "    df = pd.read_csv(df_path, header=None, names=['DateTime', 'Seconds'])\n",
    "    df = df.replace(r'[()]', '', regex=True)\n",
    "    df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs(pose_path, side_path, void_path, shock_on_path, shock_off_path, tone_on_path, tone_off_path, new_path):\n",
    "    pose_data_df = pd.read_csv(pose_path, index_col=0)\n",
    "    side_view_df = pd.read_csv(side_path , index_col=0)\n",
    "    void_data_df = pd.read_csv(void_path , index_col=0)\n",
    "    shock_on_df = pd.read_csv(shock_on_path, index_col=0)\n",
    "    shock_off_df = pd.read_csv(shock_off_path, index_col=0)\n",
    "    tone_on_df = pd.read_csv(tone_on_path, index_col=0)\n",
    "    tone_off_df = pd.read_csv(tone_off_path, index_col=0)\n",
    "\n",
    "    pose_time_df = pd.merge(pose_data_df, side_view_df, left_index=True, right_index=True)\n",
    "    pose_time_df['Is_Voiding'] = False \n",
    "\n",
    "    for voidtime in void_data_df[\"seconds\"]:\n",
    "        pose_time_df['difference'] = (pose_time_df['Seconds'] - voidtime).abs()\n",
    "\n",
    "        closest_index = pose_time_df['difference'].idxmin()\n",
    "\n",
    "        pose_time_df.loc[closest_index, 'Is_Voiding'] = True\n",
    "        pose_time_df = pose_time_df.drop(columns=[\"difference\"])\n",
    "\n",
    "    pose_time_df['Shock_Start'] = False \n",
    "    for shock_on in shock_on_df[\"side_Shock_frame\"]:\n",
    "\n",
    "        pose_time_df.loc[shock_on, 'Shock_Start'] = True\n",
    "        \n",
    "    pose_time_df['Shock_End'] = False \n",
    "    for shock_off in shock_off_df[\"side_Shock_frame\"]:\n",
    "\n",
    "        pose_time_df.loc[shock_off, 'Shock_End'] = True\n",
    "\n",
    "    pose_time_df['Tone_Start'] = False \n",
    "    for tone_on in tone_on_df[\"side_Tone_frame\"]:\n",
    "\n",
    "        pose_time_df.loc[tone_on, 'Tone_Start'] = True\n",
    "\n",
    "    pose_time_df['Tone_End'] = False \n",
    "    for tone_off in tone_off_df[\"side_Tone_frame\"]:\n",
    "\n",
    "        pose_time_df.loc[tone_off, 'Tone_End'] = True\n",
    "\n",
    "    pose_time_df.to_csv(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_18626/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n"
     ]
    }
   ],
   "source": [
    "for trial in os.listdir(dst_dir):\n",
    "    trail_path = os.path.join(dst_dir, trial)\n",
    "    \n",
    "    folders = [os.path.join(trail_path, d) for d in os.listdir(trail_path) if os.path.isdir(os.path.join(trail_path, d))]\n",
    "    for folder in folders:\n",
    "        \n",
    "        for filename in os.listdir(folder):\n",
    "            if \"Bottom_camera\" in filename:\n",
    "                bottom_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"Pose_Data\" in filename:\n",
    "                pose_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"ShockOffset\" in filename:\n",
    "                shock_off_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"ShockONset\" in filename:\n",
    "                shock_on_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"Side_view\" in filename:\n",
    "                side_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"ToneOffset\" in filename:\n",
    "                tone_off_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"ToneONset\" in filename:\n",
    "                tone_on_path = os.path.join(folder,filename)\n",
    "\n",
    "            if \"VoidTiming\" in filename:\n",
    "                void_path = os.path.join(folder,filename)\n",
    "\n",
    "\n",
    "\n",
    "        fix_pose_data(pose_path)\n",
    "        fix_void_timing(void_path)\n",
    "        fix_time_df(bottom_path)\n",
    "        fix_time_df(side_path)\n",
    "\n",
    "        new_path = os.path.join(folder, \"pose_void_tone_shock_combined.csv\")\n",
    "        combine_dfs(pose_path, side_path, void_path, shock_on_path, shock_off_path, tone_on_path, tone_off_path, new_path)\n",
    "        reduce_df(new_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

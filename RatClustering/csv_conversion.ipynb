{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been renamed, grouped into folders, and moved to the new directory.\n"
     ]
    }
   ],
   "source": [
    "# Define source and destination directories\n",
    "src_dir = \"/home/thomas/RatAnalysis/RatClustering/20240612_Footshock_Session1 copy\"\n",
    "dst_dir = \"/home/thomas/RatAnalysis/RatClustering/Footshock_Session1_Fixed\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all files in the source directory\n",
    "for filename in os.listdir(src_dir):\n",
    "    if \"filtered\" in filename:\n",
    "        continue\n",
    "\n",
    "    if 'Ai213' in filename and ('.CSV' in filename or '.csv' in filename):\n",
    "\n",
    "        start_index = filename.find('Ai213')\n",
    "        # Remove all characters before 'Ai213' and change .CSV to .csv\n",
    "        new_filename = filename[start_index:].replace('.CSV', '.csv')\n",
    "\n",
    "        # Extract the grouping pattern Ai213_x=x_#x using regex\n",
    "        match = re.search(r'Ai213_\\d+-\\d+_#\\d+', new_filename)\n",
    "        if match:\n",
    "            if \"Side_viewDLC_Resnet50\" in filename:\n",
    "                new_filename = match.group(0) + \"_Pose_Data.csv\"\n",
    "            \n",
    "            # Create a subdirectory based on the matched pattern\n",
    "            subfolder_name = match.group(0)\n",
    "            subfolder_path = os.path.join(dst_dir, subfolder_name)\n",
    "            os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "            # Construct full file paths\n",
    "            old_filepath = os.path.join(src_dir, filename)\n",
    "            new_filepath = os.path.join(subfolder_path, new_filename)\n",
    "\n",
    "            # Move and rename the file\n",
    "            shutil.copy(old_filepath, new_filepath)\n",
    "\n",
    "print(\"Files have been renamed, grouped into folders, and moved to the new directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_void_timing(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df['seconds'] = df['Var4'].str.extract(r'(\\d+\\.\\d+)')\n",
    "    df = df[['seconds']]\n",
    "    df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_pose_data(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    body_parts = df.iloc[0, 1:] \n",
    "    coords = df.iloc[1, 1:] \n",
    "\n",
    "    # Initialize an empty list to hold the new column names\n",
    "    new_columns = []\n",
    "    new_columns.append(f'Image')\n",
    "    # Create new column names based on body parts and coordinates\n",
    "    for part, coord in zip(body_parts, coords):\n",
    "        new_columns.append(f'{part}_{coord}')\n",
    "    df.columns = new_columns\n",
    "    df = df[2:]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(['Image'], axis=1)\n",
    "\n",
    "    df.to_csv(df_path)\n",
    "    # df_drop = df[[col for col in df.columns if col.endswith('_x') or col.endswith('_y')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time_df(df_path):\n",
    "    df = pd.read_csv(df_path, header=None, names=['DateTime', 'Seconds'])\n",
    "    df = df.replace(r'[()]', '', regex=True)\n",
    "    df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/tmp/ipykernel_17913/2879870463.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n"
     ]
    }
   ],
   "source": [
    "folders = [os.path.join(dst_dir, d) for d in os.listdir(dst_dir) if os.path.isdir(os.path.join(dst_dir, d))]\n",
    "for folder in folders:\n",
    "    for filename in os.listdir(folder):\n",
    "        if \"VoidTiming\" in filename:\n",
    "            fix_void_timing(os.path.join(folder,filename))\n",
    "        elif \"Pose_Data\" in filename:\n",
    "            fix_pose_data(os.path.join(folder,filename))\n",
    "        elif \"Side_view\" in filename:\n",
    "            fix_time_df(os.path.join(folder,filename))\n",
    "        elif \"Bottom_camera\" in filename:\n",
    "            fix_time_df(os.path.join(folder,filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
